[2025-10-16 23:24:38,898 I 18580 81128] core_worker_process.cc:187: Constructing CoreWorkerProcess. pid: 18580
[2025-10-16 23:24:38,901 I 18580 81128] io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2025-10-16 23:24:41,868 I 18580 81128] grpc_server.cc:137: driver server started, listening on port 49800.
[2025-10-16 23:24:41,869 I 18580 81128] core_worker.cc:526: Initializing worker at address: 127.0.0.1:49800 worker_id=01000000ffffffffffffffffffffffffffffffffffffffffffffffff node_id=0c68fd3bdbbb7de7cdddb49a9c81c23906fe48ddb7b690d2134ce7cd
[2025-10-16 23:24:41,870 I 18580 81128] task_event_buffer.cc:281: Reporting task events to GCS every 1000ms.
[2025-10-16 23:24:41,871 I 18580 64132] accessor.cc:760: Received notification for node, IsAlive = 1 node_id=0c68fd3bdbbb7de7cdddb49a9c81c23906fe48ddb7b690d2134ce7cd
[2025-10-16 23:24:41,871 I 18580 64132] core_worker.cc:5080: Number of alive nodes:1
[2025-10-16 23:24:41,871 I 18580 64132] core_worker.cc:914: Event stats:


Global stats: 10 total (3 active)
Queueing time: mean = 10.360 us, max = 54.200 us, min = 12.700 us, total = 103.600 us
Execution time:  mean = 123.450 us, total = 1.234 ms
Event stats:
	PeriodicalRunner.RunFnPeriodically - 2 total (1 active, 1 running), Execution time: mean = 5.750 us, total = 11.500 us, Queueing time: mean = 27.100 us, max = 54.200 us, min = 54.200 us, total = 54.200 us
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (0 active), Execution time: mean = 359.300 us, total = 359.300 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 18.800 us, total = 18.800 us, Queueing time: mean = 21.200 us, max = 21.200 us, min = 21.200 us, total = 21.200 us
	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 248.600 us, total = 248.600 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo - 1 total (0 active), Execution time: mean = 454.000 us, total = 454.000 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	Publisher.CheckDeadSubscribers - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 1 total (0 active), Execution time: mean = 90.900 us, total = 90.900 us, Queueing time: mean = 15.500 us, max = 15.500 us, min = 15.500 us, total = 15.500 us
	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 51.400 us, total = 51.400 us, Queueing time: mean = 12.700 us, max = 12.700 us, min = 12.700 us, total = 12.700 us

-----------------
Task execution event stats:

Global stats: 0 total (0 active)
Queueing time: mean = -nan(ind) s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
Execution time:  mean = -nan(ind) s, total = 0.000 s
Event stats:

-----------------
Task Event stats:

IO Service Stats:

Global stats: 4 total (1 active)
Queueing time: mean = 7.150 us, max = 16.100 us, min = 12.500 us, total = 28.600 us
Execution time:  mean = 126.375 us, total = 505.500 us
Event stats:
	CoreWorker.deadline_timer.flush_task_events - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	PeriodicalRunner.RunFnPeriodically - 1 total (0 active), Execution time: mean = 125.100 us, total = 125.100 us, Queueing time: mean = 16.100 us, max = 16.100 us, min = 16.100 us, total = 16.100 us
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData.OnReplyReceived - 1 total (0 active), Execution time: mean = 14.600 us, total = 14.600 us, Queueing time: mean = 12.500 us, max = 12.500 us, min = 12.500 us, total = 12.500 us
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData - 1 total (0 active), Execution time: mean = 365.800 us, total = 365.800 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
Other Stats:
	grpc_in_progress:0
	current number of task status events in buffer: 1
	current number of profile events in buffer: 0
	current number of dropped task attempts tracked: 0
	total task events sent: 0 MiB
	total number of task attempts sent: 0
	total number of task attempts dropped reported: 0
	total number of sent failure: 0
	num status task events dropped: 0
	num profile task events dropped: 0


[2025-10-16 23:24:41,874 I 18580 81128] event.cc:500: Ray Event initialized for CORE_WORKER
[2025-10-16 23:24:41,874 I 18580 81128] event.cc:500: Ray Event initialized for EXPORT_TASK
[2025-10-16 23:24:41,874 I 18580 81128] event.cc:331: Set ray event level to warning
[2025-10-16 23:24:50,984 W 18580 35712] metric_exporter.cc:105: [1] Export metrics to agent failed: RpcError: RPC Error message: failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:65386: Connection refused; RPC Error details: . This won't affect Ray, but you can lose metrics from the cluster.
[2025-10-16 23:24:57,573 I 18580 81128] core_worker.cc:1102: Sending disconnect message to the local raylet.
[2025-10-16 23:24:57,574 I 18580 81128] raylet_client.cc:73: RayletClient::Disconnect, exit_type=INTENDED_USER_EXIT, exit_detail=Shutdown by ray.shutdown()., has creation_task_exception_pb_bytes=0
[2025-10-16 23:24:57,574 I 18580 81128] core_worker.cc:1108: Disconnected from the local raylet.
[2025-10-16 23:24:57,574 I 18580 81128] core_worker.cc:1017: Shutting down a core worker.
[2025-10-16 23:24:57,574 I 18580 81128] task_event_buffer.cc:292: Shutting down TaskEventBuffer.
[2025-10-16 23:24:57,574 I 18580 54636] task_event_buffer.cc:260: Task event buffer io service stopped.
[2025-10-16 23:24:57,575 I 18580 81128] core_worker.cc:1039: Waiting for joining a core worker io thread. If it hangs here, there might be deadlock or a high load in the core worker io service.
[2025-10-16 23:24:57,575 I 18580 64132] core_worker.cc:1275: Core worker main io service stopped.
[2025-10-16 23:24:57,584 I 18580 81128] core_worker.cc:1051: Disconnecting a GCS client.
[2025-10-16 23:24:57,584 I 18580 81128] core_worker.cc:1058: Core worker ready to be deallocated.
[2025-10-16 23:24:57,584 I 18580 81128] core_worker.cc:1008: Core worker is destructed
[2025-10-16 23:24:57,584 I 18580 81128] task_event_buffer.cc:292: Shutting down TaskEventBuffer.
[2025-10-16 23:24:57,585 W 18580 21936] server_call.h:334: [1] Not sending reply because executor stopped.
[2025-10-16 23:24:57,834 I 18580 81128] core_worker_process.cc:232: Destructing CoreWorkerProcessImpl. pid: 18580
[2025-10-16 23:24:57,834 I 18580 81128] io_service_pool.cc:47: IOServicePool is stopped.
[2025-10-16 23:24:58,050 I 18580 81128] stats.h:120: Stats module has shutdown.
