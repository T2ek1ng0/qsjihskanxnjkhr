[2025-10-16 23:12:37,454 I 54560 46132] core_worker_process.cc:187: Constructing CoreWorkerProcess. pid: 54560
[2025-10-16 23:12:37,457 I 54560 46132] io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2025-10-16 23:12:40,446 I 54560 46132] grpc_server.cc:137: driver server started, listening on port 49678.
[2025-10-16 23:12:40,447 I 54560 46132] core_worker.cc:526: Initializing worker at address: 127.0.0.1:49678 worker_id=01000000ffffffffffffffffffffffffffffffffffffffffffffffff node_id=8e2cf67ec3b685d76b7307ca6796d76d9bfca1988ebebd2c10e3aeeb
[2025-10-16 23:12:40,448 I 54560 46132] task_event_buffer.cc:281: Reporting task events to GCS every 1000ms.
[2025-10-16 23:12:40,449 I 54560 76688] accessor.cc:760: Received notification for node, IsAlive = 1 node_id=8e2cf67ec3b685d76b7307ca6796d76d9bfca1988ebebd2c10e3aeeb
[2025-10-16 23:12:40,449 I 54560 76688] core_worker.cc:5080: Number of alive nodes:1
[2025-10-16 23:12:40,450 I 54560 76688] core_worker.cc:914: Event stats:


Global stats: 10 total (3 active)
Queueing time: mean = 6.960 us, max = 23.700 us, min = 13.200 us, total = 69.600 us
Execution time:  mean = 131.380 us, total = 1.314 ms
Event stats:
	PeriodicalRunner.RunFnPeriodically - 2 total (1 active, 1 running), Execution time: mean = 6.650 us, total = 13.300 us, Queueing time: mean = 6.750 us, max = 13.500 us, min = 13.500 us, total = 13.500 us
	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 310.600 us, total = 310.600 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 19.600 us, total = 19.600 us, Queueing time: mean = 19.200 us, max = 19.200 us, min = 19.200 us, total = 19.200 us
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 1 total (0 active), Execution time: mean = 162.300 us, total = 162.300 us, Queueing time: mean = 23.700 us, max = 23.700 us, min = 23.700 us, total = 23.700 us
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo - 1 total (0 active), Execution time: mean = 415.300 us, total = 415.300 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	Publisher.CheckDeadSubscribers - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 61.400 us, total = 61.400 us, Queueing time: mean = 13.200 us, max = 13.200 us, min = 13.200 us, total = 13.200 us
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (0 active), Execution time: mean = 331.300 us, total = 331.300 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s

-----------------
Task execution event stats:

Global stats: 0 total (0 active)
Queueing time: mean = -nan(ind) s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
Execution time:  mean = -nan(ind) s, total = 0.000 s
Event stats:

-----------------
Task Event stats:

IO Service Stats:

Global stats: 4 total (1 active)
Queueing time: mean = 22.350 us, max = 68.600 us, min = 20.800 us, total = 89.400 us
Execution time:  mean = 104.850 us, total = 419.400 us
Event stats:
	PeriodicalRunner.RunFnPeriodically - 1 total (0 active), Execution time: mean = 117.100 us, total = 117.100 us, Queueing time: mean = 68.600 us, max = 68.600 us, min = 68.600 us, total = 68.600 us
	CoreWorker.deadline_timer.flush_task_events - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData - 1 total (0 active), Execution time: mean = 285.800 us, total = 285.800 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData.OnReplyReceived - 1 total (0 active), Execution time: mean = 16.500 us, total = 16.500 us, Queueing time: mean = 20.800 us, max = 20.800 us, min = 20.800 us, total = 20.800 us
Other Stats:
	grpc_in_progress:0
	current number of task status events in buffer: 1
	current number of profile events in buffer: 0
	current number of dropped task attempts tracked: 0
	total task events sent: 0 MiB
	total number of task attempts sent: 0
	total number of task attempts dropped reported: 0
	total number of sent failure: 0
	num status task events dropped: 0
	num profile task events dropped: 0


[2025-10-16 23:12:40,452 I 54560 46132] event.cc:500: Ray Event initialized for CORE_WORKER
[2025-10-16 23:12:40,453 I 54560 46132] event.cc:500: Ray Event initialized for EXPORT_TASK
[2025-10-16 23:12:40,453 I 54560 46132] event.cc:331: Set ray event level to warning
[2025-10-16 23:12:49,623 W 54560 67320] metric_exporter.cc:105: [1] Export metrics to agent failed: RpcError: RPC Error message: failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:50004: Connection refused; RPC Error details: . This won't affect Ray, but you can lose metrics from the cluster.
[2025-10-16 23:12:55,905 I 54560 46132] core_worker.cc:1102: Sending disconnect message to the local raylet.
[2025-10-16 23:12:55,905 I 54560 46132] raylet_client.cc:73: RayletClient::Disconnect, exit_type=INTENDED_USER_EXIT, exit_detail=Shutdown by ray.shutdown()., has creation_task_exception_pb_bytes=0
[2025-10-16 23:12:55,905 I 54560 46132] core_worker.cc:1108: Disconnected from the local raylet.
[2025-10-16 23:12:55,905 I 54560 46132] core_worker.cc:1017: Shutting down a core worker.
[2025-10-16 23:12:55,905 I 54560 46132] task_event_buffer.cc:292: Shutting down TaskEventBuffer.
[2025-10-16 23:12:55,905 I 54560 39484] task_event_buffer.cc:260: Task event buffer io service stopped.
[2025-10-16 23:12:55,906 I 54560 46132] core_worker.cc:1039: Waiting for joining a core worker io thread. If it hangs here, there might be deadlock or a high load in the core worker io service.
[2025-10-16 23:12:55,906 I 54560 76688] core_worker.cc:1275: Core worker main io service stopped.
[2025-10-16 23:12:55,912 I 54560 46132] core_worker.cc:1051: Disconnecting a GCS client.
[2025-10-16 23:12:55,912 I 54560 46132] core_worker.cc:1058: Core worker ready to be deallocated.
[2025-10-16 23:12:55,912 I 54560 46132] core_worker.cc:1008: Core worker is destructed
[2025-10-16 23:12:55,912 I 54560 46132] task_event_buffer.cc:292: Shutting down TaskEventBuffer.
[2025-10-16 23:12:55,912 W 54560 69616] server_call.h:334: [1] Not sending reply because executor stopped.
[2025-10-16 23:12:56,170 I 54560 46132] core_worker_process.cc:232: Destructing CoreWorkerProcessImpl. pid: 54560
[2025-10-16 23:12:56,171 I 54560 46132] io_service_pool.cc:47: IOServicePool is stopped.
[2025-10-16 23:12:56,372 I 54560 46132] stats.h:120: Stats module has shutdown.
