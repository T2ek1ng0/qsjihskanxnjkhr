[2025-10-16 23:08:39,761 I 15752 78148] core_worker_process.cc:187: Constructing CoreWorkerProcess. pid: 15752
[2025-10-16 23:08:39,766 I 15752 78148] io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2025-10-16 23:08:42,999 I 15752 78148] grpc_server.cc:137: driver server started, listening on port 60443.
[2025-10-16 23:08:43,000 I 15752 78148] core_worker.cc:526: Initializing worker at address: 127.0.0.1:60443 worker_id=01000000ffffffffffffffffffffffffffffffffffffffffffffffff node_id=729f71eab2186e545850979d054f69fa84fc0f7028e87e3d6af4f9c8
[2025-10-16 23:08:43,002 I 15752 78148] task_event_buffer.cc:281: Reporting task events to GCS every 1000ms.
[2025-10-16 23:08:43,003 I 15752 63920] accessor.cc:760: Received notification for node, IsAlive = 1 node_id=729f71eab2186e545850979d054f69fa84fc0f7028e87e3d6af4f9c8
[2025-10-16 23:08:43,003 I 15752 63920] core_worker.cc:5080: Number of alive nodes:1
[2025-10-16 23:08:43,003 I 15752 63920] core_worker.cc:914: Event stats:


Global stats: 10 total (3 active)
Queueing time: mean = 6.250 us, max = 21.200 us, min = 10.900 us, total = 62.500 us
Execution time:  mean = 150.360 us, total = 1.504 ms
Event stats:
	PeriodicalRunner.RunFnPeriodically - 2 total (1 active, 1 running), Execution time: mean = 5.600 us, total = 11.200 us, Queueing time: mean = 5.450 us, max = 10.900 us, min = 10.900 us, total = 10.900 us
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 1 total (0 active), Execution time: mean = 98.500 us, total = 98.500 us, Queueing time: mean = 13.200 us, max = 13.200 us, min = 13.200 us, total = 13.200 us
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo - 1 total (0 active), Execution time: mean = 608.400 us, total = 608.400 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	Publisher.CheckDeadSubscribers - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (0 active), Execution time: mean = 438.700 us, total = 438.700 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 59.800 us, total = 59.800 us, Queueing time: mean = 17.200 us, max = 17.200 us, min = 17.200 us, total = 17.200 us
	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 271.300 us, total = 271.300 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::WorkerInfoGcsService.grpc_client.AddWorkerInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 15.700 us, total = 15.700 us, Queueing time: mean = 21.200 us, max = 21.200 us, min = 21.200 us, total = 21.200 us
	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s

-----------------
Task execution event stats:

Global stats: 0 total (0 active)
Queueing time: mean = -nan(ind) s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
Execution time:  mean = -nan(ind) s, total = 0.000 s
Event stats:

-----------------
Task Event stats:

IO Service Stats:

Global stats: 4 total (1 active)
Queueing time: mean = 8.500 us, max = 18.500 us, min = 15.500 us, total = 34.000 us
Execution time:  mean = 135.825 us, total = 543.300 us
Event stats:
	PeriodicalRunner.RunFnPeriodically - 1 total (0 active), Execution time: mean = 123.000 us, total = 123.000 us, Queueing time: mean = 15.500 us, max = 15.500 us, min = 15.500 us, total = 15.500 us
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData - 1 total (0 active), Execution time: mean = 405.700 us, total = 405.700 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
	ray::rpc::TaskInfoGcsService.grpc_client.AddTaskEventData.OnReplyReceived - 1 total (0 active), Execution time: mean = 14.600 us, total = 14.600 us, Queueing time: mean = 18.500 us, max = 18.500 us, min = 18.500 us, total = 18.500 us
	CoreWorker.deadline_timer.flush_task_events - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
Other Stats:
	grpc_in_progress:0
	current number of task status events in buffer: 1
	current number of profile events in buffer: 0
	current number of dropped task attempts tracked: 0
	total task events sent: 0 MiB
	total number of task attempts sent: 0
	total number of task attempts dropped reported: 0
	total number of sent failure: 0
	num status task events dropped: 0
	num profile task events dropped: 0


[2025-10-16 23:08:43,006 I 15752 78148] event.cc:500: Ray Event initialized for CORE_WORKER
[2025-10-16 23:08:43,007 I 15752 78148] event.cc:500: Ray Event initialized for EXPORT_TASK
[2025-10-16 23:08:43,007 I 15752 78148] event.cc:331: Set ray event level to warning
[2025-10-16 23:08:51,920 W 15752 79312] metric_exporter.cc:105: [1] Export metrics to agent failed: RpcError: RPC Error message: failed to connect to all addresses; last error: UNAVAILABLE: ipv4:127.0.0.1:61356: Connection refused; RPC Error details: . This won't affect Ray, but you can lose metrics from the cluster.
[2025-10-16 23:08:58,808 I 15752 78148] core_worker.cc:1102: Sending disconnect message to the local raylet.
[2025-10-16 23:08:58,808 I 15752 78148] raylet_client.cc:73: RayletClient::Disconnect, exit_type=INTENDED_USER_EXIT, exit_detail=Shutdown by ray.shutdown()., has creation_task_exception_pb_bytes=0
[2025-10-16 23:08:58,809 I 15752 78148] core_worker.cc:1108: Disconnected from the local raylet.
[2025-10-16 23:08:58,809 I 15752 78148] core_worker.cc:1017: Shutting down a core worker.
[2025-10-16 23:08:58,809 I 15752 78148] task_event_buffer.cc:292: Shutting down TaskEventBuffer.
[2025-10-16 23:08:58,809 I 15752 46592] task_event_buffer.cc:260: Task event buffer io service stopped.
[2025-10-16 23:08:58,809 I 15752 78148] core_worker.cc:1039: Waiting for joining a core worker io thread. If it hangs here, there might be deadlock or a high load in the core worker io service.
[2025-10-16 23:08:58,809 I 15752 63920] core_worker.cc:1275: Core worker main io service stopped.
[2025-10-16 23:08:58,819 I 15752 78148] core_worker.cc:1051: Disconnecting a GCS client.
[2025-10-16 23:08:58,819 I 15752 78148] core_worker.cc:1058: Core worker ready to be deallocated.
[2025-10-16 23:08:58,819 I 15752 78148] core_worker.cc:1008: Core worker is destructed
[2025-10-16 23:08:58,819 I 15752 78148] task_event_buffer.cc:292: Shutting down TaskEventBuffer.
[2025-10-16 23:08:58,819 W 15752 63912] server_call.h:334: [1] Not sending reply because executor stopped.
[2025-10-16 23:08:59,068 I 15752 78148] core_worker_process.cc:232: Destructing CoreWorkerProcessImpl. pid: 15752
[2025-10-16 23:08:59,068 I 15752 78148] io_service_pool.cc:47: IOServicePool is stopped.
[2025-10-16 23:08:59,206 I 15752 78148] stats.h:120: Stats module has shutdown.
